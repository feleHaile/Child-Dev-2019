{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from pandas import read_stata\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg', warn=False)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimize_multi(f, start=None, **vargs):\n",
    "  def expanded_f(*args):\n",
    "    return f(args)\n",
    "  return minimize(expanded_f, start=start, method=\"L-BFGS-B\", **vargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Table.read_table('Young Lives R1....csv')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nans from pertinent columns\n",
    "dataframe = data.to_df()\n",
    "altered = dataframe.fillna(-99)\n",
    "data = Table.from_df(altered)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression\n",
    "\n",
    "<font color=\"Blue\"> Another way to predict outcomes is with multivariate regression.  Prepare two multivariate regressions to compare: one regression will have all the variables you think are important and the other will have variables you think are not important.  Compare the R^2 of these regressions.  Were you right? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the steps to building multivariate regression examining how age and sex predict height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure all your data is in integer format and keep only observations with height, age & sex data\n",
    "data[\"chheight_r1\"]=data.apply(int, 'chheight_r1')\n",
    "data[\"agechild_r1\"]=data.apply(int, 'agechild_r1')\n",
    "data[\"agemum_r1\"]=data.apply(int, 'agemum_r1')\n",
    "# Make a column that will be associated with the intercept\n",
    "data[\"For Intercept\"]=1\n",
    "\n",
    "# Select all the variables you want to analyze including intercept and outcome.\n",
    "# (Until we have the correct minimizing function, just include one variable and the outcome.)\n",
    "Regression1=data.select(\"...\",\"...\",\"...\",\"For Intercept\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing\n",
    "Regression1=Regression1.where(Regression1['...']>0)\n",
    "Regression1=Regression1.where(Regression1['...']>0)\n",
    "Regression1=Regression1.where(Regression1['...']>0)\n",
    "Regression1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the table in two: predictor variables (sex & age) & outcome variable (height)\n",
    "X_features_table =Regression1.drop(\"chheight_r1\")\n",
    "X_true_values = Regression1.column(\"chheight_r1\") # note: this is an array\n",
    "X_features_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some intial values for maximizing the coefficients \n",
    "# An easy choice is all 0's.  \n",
    "# There will be the same number of coefficients as there are predictors - a slope for each predictor.\n",
    "X_initial_coefficient_guess = np.zeros(X_features_table.num_columns)\n",
    "X_initial_coefficient_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_all(features_table, coefficients):\n",
    "    \"\"\"\n",
    "    Given a table of features called features_table and some coefficients,\n",
    "    produces linear predictions for each row of features_table.\n",
    "    \n",
    "    features_table should be a table with one column for each feature\n",
    "    being used to predict.  Each row represents a house in the task\n",
    "    we're doing in this lab.\n",
    "    \n",
    "    coefficients should be an array with one element for each column in\n",
    "    features_table, like the coefficients computed by the function\n",
    "    least_squares_coefficients.\n",
    "    \n",
    "    Returns an array of predictions, one for each row of features_table.\n",
    "    \n",
    "    If there were 3 rows in features_table, we would return a 3-element\n",
    "    array instead, containing the predicted prices for each row.\n",
    "    \"\"\"\n",
    "   # assert features_table.num_columns == len(coefficients), /\n",
    "    \"\"\"\n",
    "    The first argument to predict_all should be a table with one\n",
    "    column for each feature.  That means it should have the same\n",
    "    number of columns as the coefficients array (the second\n",
    "    argument) has elements.\n",
    "    \"\"\"\n",
    "    def predict(features):\n",
    "        # Given an array of features, produce one prediction.\n",
    "        return sum(features * coefficients)\n",
    "    predictions = Table().with_column('features', features_table.rows).apply(predict, 'features')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predictions=predict_all(X_features_table, X_initial_coefficient_guess)\n",
    "X_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the initial coefficient guess up above to make a different prediction!\n",
    "X_new_coefficient_guess = [1]\n",
    "X_predictions=predict_all(X_features_table, X_new_coefficient_guess)\n",
    "X_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_errors(features_table, coefficients, true_values):\n",
    "    \"\"\"\n",
    "    Computes the prediction errors for a linear model with the given\n",
    "    coefficients when predicting the true values for the given\n",
    "    examples.\n",
    "    \n",
    "    features_table should be a table with one column for each feature\n",
    "    being used to predict.  \n",
    "    \n",
    "    coefficients should be an array of numbers, one for each feature.\n",
    "    \n",
    "    true_values should be an array of numbers, one for each row in\n",
    "    features_table.  It records the true prices of each house.\n",
    "    \"\"\"\n",
    "    return predict_all(features_table, coefficients) - true_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_errors=compute_errors(X_features_table, X_initial_coefficient_guess, X_true_values)\n",
    "X_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(errors):\n",
    "    \"\"\"\n",
    "    Computes the root mean squared error when a regression model makes\n",
    "    the given errors.  So errors should be an array of numbers, one for\n",
    "    each row in some data table for which we're computing predictions.  \n",
    "    Each number is the prediction error of some regression model.\n",
    "    \"\"\"\n",
    "    return np.mean(errors**2)**0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=rmse(X_errors)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_least_squares_objective_function(features_table, true_values):\n",
    "    \"\"\"\n",
    "    Makes an objective function for main data in the features_table\n",
    "    table, where the true values we're trying to predict are true_values.\n",
    "    \n",
    "    features_table should be a table with one column for each feature\n",
    "    being used to predict.  \n",
    "    \n",
    "    true_values should be an array of numbers, one for each row in\n",
    "    features_table.  \n",
    "    \n",
    "    The returned value is a function.  That function takes an array of\n",
    "    coefficients and returns a number.  Larger values of that number\n",
    "    mean that those coefficients produce worse prediction errors.\n",
    "    \"\"\"\n",
    "    def objective_function(coefficients):\n",
    "        errors = compute_errors(features_table, np.array(coefficients), true_values)\n",
    "        return rmse(errors)\n",
    "    return objective_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_objective_function = make_least_squares_objective_function(X_features_table, X_true_values)\n",
    "X_objective_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_coefficients(main_data, predicted_column_name):\n",
    "    \"\"\"\n",
    "    Performs multiple linear regression predicting predicted_column_name\n",
    "    using the other columns of main_data as features.\n",
    "    \n",
    "    main_data should be a table with one column for each feature\n",
    "    being used to predict, plus one column for the value we're trying\n",
    "    to predict.  That column's name should equal predicted_column_name.\n",
    "    Each row represents a house in the task we're doing in this lab.\n",
    "    \n",
    "    predicted_column_name should be a string, the name of the column in\n",
    "    main_data that we're trying to predict.\n",
    "    \n",
    "    Returns an array of coefficients, one for each feature (that is, one\n",
    "    for each column in main_data other than predicted_column_name).\n",
    "    \n",
    "    For example, if main_data has 3 columns, mom's education, age, and height,\n",
    "    and predicted_column_name is \"Price\", then we will use mom's education and\n",
    "    age to predict height.  This function will return an array of 2\n",
    "    numbers, a regression coefficient for mom's education and a\n",
    "    regression coefficient for age.\n",
    "    \"\"\"\n",
    "    features_table = main_data.drop(predicted_column_name)\n",
    "    true_values = main_data.column(predicted_column_name)\n",
    "    objective_function_OLS = make_least_squares_objective_function(features_table, true_values)\n",
    "    \n",
    "    # Now we find the coefficients that produce the smallest\n",
    "    # error.\n",
    "    initial_coefficient_guess = np.zeros(features_table.num_columns)\n",
    "    best_coefficients = minimize_multi(objective_function_OLS, start=initial_coefficient_guess)\n",
    "    if features_table.num_columns == 1:\n",
    "        return np.array([best_coefficients])\n",
    "    else:\n",
    "        return best_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_best_coefficients = minimize_multi(X_objective_function, start=X_initial_coefficient_guess)\n",
    "X_best_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_Coefficients = least_squares_coefficients(Regression1, '...')\n",
    "My_Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well our model fits the data.  We will calculate the R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_height=np.average(Regression1[\"...\"])\n",
    "mean_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_predictions=predict_all(X_features_table, My_Coefficients)\n",
    "Regression1[\"Predicted\"]=My_predictions\n",
    "Regression1[\"Diff_Predict_SQ\"]=(Regression1[\"...\"]-Regression1[\"Predicted\"])**2\n",
    "Regression1[\"Diff_True_SQ\"]=(Regression1[\"...\"]-mean_height)**2\n",
    "Regression1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared=1-np.sum(Regression1[\"Diff_Predict_SQ\"])/np.sum(Regression1[\"Diff_True_SQ\"])\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be more systematic about building the model - we will add variables to try to get the largest R^2.  Adding more covariates will improve the fit of the model, but we are also making the model more complex.  Let's add covariates in order of importance, keeping those that increase the adjusted R^2.  The formula for the adjusted R^2 is 1-(1-R^2)(N-1)/(N-p-1), where N= sample size and p= number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is of correlation, not causation.  But since this is a first indication of a potential causal relationship, we may as well try a policy and then later see if it works out. <font color=\"Blue\"> If you were attempting to change the outcome based on changing the feature, which feature would you try to change?  Don't just consider the one with the highest correlation, but also take into account costs and difficulty of changing the feature. (Not a data exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
